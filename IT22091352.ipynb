{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eefaedc-bfdf-4c31-8882-e634d0a42096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d36201-9008-470b-896b-bca47c11161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b795d206-f02e-4865-a03e-73c05bbc0f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Cancer_Data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca71ba-fa6c-4543-a764-d813123ff05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ef35aa-0f86-4775-bde6-c4e2c929e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. DATA PREPROCESSING AND FEATURE ENGINEERING (10% WEIGHT) ---\n",
    "\n",
    "# Identify Features (X) and Target (Y)\n",
    "# Drop the non-predictive 'id' column and the target variable 'diagnosis' from features [1]\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "Y = data['diagnosis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ea4d9b-6cb0-46d4-bd09-8f5d56e45183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Target Encoding (Malignant/Benign -> 1/0)\n",
    "# Deep Learning models require numerical input for the target variable [2]\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y) # 'M' -> 1, 'B' -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c366b3b-453c-4d65-be66-00ee3d080782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data preprocessing complete. Features standardized, Target encoded (M=1, B=0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\extmath.py:1144: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\extmath.py:1149: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\extmath.py:1169: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# 3.2. Feature Standardization (Scaling)\n",
    "# Scaling is crucial for optimizing gradient descent convergence in deep networks [2]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"\\nData preprocessing complete. Features standardized, Target encoded (M=1, B=0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06156454-2a6d-4b89-9221-f299167ddbec",
   "metadata": {},
   "source": [
    "# 4. DATA PREPARATION (TRAIN, VALIDATION, TEST SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054098ae-94fa-46f4-8143-6dc4ed4af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into Training (70%), Validation (15%), and Test (15%) sets.\n",
    "# We use stratification to ensure the class distribution is maintained across all subsets.\n",
    "TEST_SIZE_FINAL = 0.15 # 15% for final, unbiased evaluation\n",
    "VAL_SIZE_RATIO = 0.1764 # (0.15 / 0.85) to get 15% of the total in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c263c5aa-394f-40ac-aacc-c9c702a6523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split Full Training Set (85%) and Test Set (15%)\n",
    "X_train_full, X_test, Y_train_full, Y_test = train_test_split(\n",
    "    X_scaled, encoded_Y, test_size=TEST_SIZE_FINAL, random_state=42, stratify=encoded_Y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61fadf13-8ae5-4a7a-9248-b1b1710ae80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Training Set into Training (70%) and Validation (15%)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_full, Y_train_full, test_size=VAL_SIZE_RATIO, random_state=42, stratify=Y_train_full\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f64ae3f3-7060-4169-a63f-50b8055ff97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: (569, 33)\n",
      "Training Samples (70%): (397, 31)\n",
      "Validation Samples (15%): (86, 31)\n",
      "Test Samples (15%): (86, 31)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(f\"Total Samples: {data.shape}\")\n",
    "print(f\"Training Samples (70%): {X_train.shape}\")\n",
    "print(f\"Validation Samples (15%): {X_val.shape}\")\n",
    "print(f\"Test Samples (15%): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dad6437-12bb-40c7-99b8-54d68c67bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture (DNN Baseline):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Baseline_DNN_M1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Baseline_DNN_M1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 5. MODEL SELECTION AND ARCHITECTURE (10% WEIGHT) ---\n",
    "\n",
    "# Member 1: Standard Deep Multi-Layer Perceptron (MLP) using Sequential API.\n",
    "# This serves as the deep learning baseline model.\n",
    "\n",
    "def create_baseline_dnn(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ], name=\"Baseline_DNN_M1\")\n",
    "    return model\n",
    "\n",
    "model_m1 = create_baseline_dnn(input_dim)\n",
    "print(\"\\nModel Architecture (DNN Baseline):\")\n",
    "model_m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06eacdc3-7daf-448a-a1be-e036f85b9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. MODEL COMPILATION ---\n",
    "\n",
    "# Use Adam optimizer and Binary Cross-Entropy loss for binary classification [2]\n",
    "# Include AUC-ROC as a critical performance metric (AUC is robust against class imbalance)\n",
    "model_m1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "100c22b5-936b-463e-a948-a770f7574780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. MODEL TRAINING ---\n",
    "\n",
    "# Use Early Stopping to halt training if validation loss plateaus, restoring the best weights [3]\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd866ea2-52d5-4a23-ae3b-fe6ac8c5cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Model Training...\n",
      "Epoch 1/200\n",
      "13/13 - 4s - 285ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 2/200\n",
      "13/13 - 0s - 27ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 3/200\n",
      "13/13 - 1s - 54ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 4/200\n",
      "13/13 - 1s - 51ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 5/200\n",
      "13/13 - 0s - 31ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 6/200\n",
      "13/13 - 1s - 50ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 7/200\n",
      "13/13 - 1s - 49ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 8/200\n",
      "13/13 - 0s - 26ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 9/200\n",
      "13/13 - 1s - 48ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 10/200\n",
      "13/13 - 0s - 31ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 11/200\n",
      "13/13 - 1s - 44ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 12/200\n",
      "13/13 - 1s - 56ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 13/200\n",
      "13/13 - 1s - 44ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 14/200\n",
      "13/13 - 1s - 50ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 15/200\n",
      "13/13 - 1s - 55ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Epoch 16/200\n",
      "13/13 - 0s - 25ms/step - accuracy: 0.6272 - auc: 0.0000e+00 - loss: nan - val_accuracy: 0.6279 - val_auc: 0.0000e+00 - val_loss: nan\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Model Training...\")\n",
    "history_m1 = model_m1.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=200,             # Set a high number of epochs, relying on EarlyStopping\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2               # Display training progress per epoch\n",
    ")\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05f1bff9-6e21-4885-9de3-5aa36af9779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model on the held-out Test Set (15%):\n",
      "\n",
      "--- Member 1 (Baseline DNN) Final Test Results ---\n",
      "Test Loss: nan\n",
      "Test Accuracy: 0.6279\n",
      "Test AUC-ROC: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 8. MODEL EVALUATION (5% WEIGHT) ---\n",
    "\n",
    "print(\"\\nEvaluating Model on the held-out Test Set (15%):\")\n",
    "loss_m1, accuracy_m1, auc_m1 = model_m1.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(f\"\\n--- Member 1 (Baseline DNN) Final Test Results ---\")\n",
    "print(f\"Test Loss: {loss_m1:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_m1:.4f}\")\n",
    "print(f\"Test AUC-ROC: {auc_m1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5cbda3e-b908-445f-a73d-e1a680e378ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step \n"
     ]
    }
   ],
   "source": [
    "# Generate detailed classification report and confusion matrix\n",
    "Y_pred_prob = model_m1.predict(X_test)\n",
    "Y_pred_class = (Y_pred_prob > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5523bed5-8444-41ea-8459-5b2e0534818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[54  0]\n",
      " [32  0]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred_class)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a32dbd46-9a2a-4c26-b963-ce48db20bca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Key Metrics for Comparison):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.63      1.00      0.77        54\n",
      "           M       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.63        86\n",
      "   macro avg       0.31      0.50      0.39        86\n",
      "weighted avg       0.39      0.63      0.48        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Calculate Classification Report (Precision, Recall, F1-Score)\n",
    "target_names = encoder.classes_\n",
    "report = classification_report(Y_test, Y_pred_class, target_names=target_names)\n",
    "print(\"\\nClassification Report (Key Metrics for Comparison):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4798777-1b1b-4973-be67-b5ed174160b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
