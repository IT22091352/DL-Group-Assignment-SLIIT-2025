{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436c8b81-f695-49ca-afde-6577983506a5",
   "metadata": {},
   "source": [
    "## 1. SETUP AND IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4129d52a-5dcc-463d-b7a7-5fa73dbc64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: keras in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (3.11.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kdgim\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eefaedc-bfdf-4c31-8882-e634d0a42096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d36201-9008-470b-896b-bca47c11161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b795d206-f02e-4865-a03e-73c05bbc0f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Cancer_Data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4e233b-4d74-4a7d-a834-4ca63c06804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7bdbb-59e7-4aa6-a7ce-a9d97b22648c",
   "metadata": {},
   "source": [
    "## 2. DATA LOADING AND INITIAL CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554abc8e-ac46-4a30-9c7e-cdc0fc1f2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'Cancer_Data.csv' not found. Please ensure the file is in the correct directory.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     exit()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Identify Features (X) and Target (Y)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [1]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m Y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('/workspaces/DL-Group-Assignment-SLIIT-2025/Cancer_Data.csv') # [1]\n",
    "    \n",
    "    # Check for the common redundant column (often unnamed at index 32) and drop it\n",
    "    if 'Unnamed: 32' in data.columns:\n",
    "        data = data.drop(['Unnamed: 32'], axis=1) \n",
    "        \n",
    "    print(f\"Dataset shape: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Cancer_Data.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# Identify Features (X) and Target (Y)\n",
    "X = data.drop(['id', 'diagnosis'], axis=1) # [1]\n",
    "Y = data['diagnosis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a1de1-dcea-47fd-9a63-c6ec0168b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdf55c-587e-435b-b127-b308eb8d9194",
   "metadata": {},
   "source": [
    "## 3. EXPLORATORY DATA ANALYSIS (EDA) AND VISUALIZATIONS (5% Grading Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076c74e-5115-4141-8028-4017f60db071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1. Target Class Distribution\n",
    "print(\"\\n--- EDA: Target Class Distribution ---\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='diagnosis', data=data, palette='viridis')\n",
    "plt.title('Distribution of Diagnosis (Malignant vs. Benign)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b7034-6d93-46c5-9caf-2c31ee75f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the info about data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e7b65-55f4-442b-bc06-6b87d4752f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Feature Correlation Heatmap\n",
    "data_corr = data.copy()\n",
    "data_corr['diagnosis'] = data_corr['diagnosis'].replace({'M': 1, 'B': 0}) \n",
    "mean_features = ['diagnosis'] + [col for col in data_corr.columns if 'mean' in col]\n",
    "corr_matrix = data_corr[mean_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0e37b-e3fa-4bad-9cb9-387406fd2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8)) \n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.1f', cmap='coolwarm', \n",
    "            linewidths=.5, linecolor='black')\n",
    "plt.title('Correlation Heatmap of Mean Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1224f41-0f47-48a1-9799-db38fc521511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr['diagnosis'].value_counts()    # Begineer cancer -> 0 and Maligant Cancer -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186673ff-c679-4a2f-80c4-80fa9728b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "# First, convert the diagnosis column to numeric values\n",
    "# Assuming 'M' is Malignant (1) and other values (like 'B' for Benign) are 0\n",
    "df['diagnosis_numeric'] = df['diagnosis'].map({'M': 1, 'B': 0})  # Adjust mapping as needed\n",
    "\n",
    "# Calculate correlational matrix using the numeric version\n",
    "corr_matrix = df.corr(numeric_only=True)  # Ensure only numeric columns are used\n",
    "\n",
    "# Use the numeric version of diagnosis for correlation\n",
    "corr_target = corr_matrix['diagnosis_numeric']\n",
    "\n",
    "# Filter for correlations greater than 0.5\n",
    "corr_best = corr_target[corr_target > 0.5]\n",
    "\n",
    "corr_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38eca7-e28f-473e-a0a1-4aaea8f7653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to show the correlation with x and y labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr_best.plot(kind='bar')\n",
    "plt.title('Correlation with Target Variable')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11444297-6d0b-4bc8-b6a4-d442a22a7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Distribution of a Key Feature (Radius Mean) by Diagnosis\n",
    "print(\"\\n--- EDA: Distribution of Radius Mean (Malignant vs. Benign) ---\")\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.violinplot(x='diagnosis', y='radius_mean', data=data, palette=['lightcoral', 'skyblue']) #\n",
    "plt.title('Radius Mean Distribution by Diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c950ea5-4cd4-4dfd-a5ff-cf2aa93ab783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DATA PREPROCESSING (10% Grading Weight) ---\n",
    "# 4.1. Target Encoding \n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(Y) # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896f408-27f1-4fc7-b4e2-57e47d759bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE_FINAL = 0.15 \n",
    "VAL_SIZE_RATIO = 0.1764 # (~15% of total samples for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166d774-5d03-4469-a75d-260be772a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8b313-2c41-4552-bd60-80c929d3cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split Full Training Set (85%) and Test Set (15%), stratified\n",
    "X_train_full, X_test, Y_train_full, Y_test = train_test_split(\n",
    "    X.values, encoded_Y, test_size=TEST_SIZE_FINAL, random_state=42, stratify=encoded_Y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc417f-9c86-4eb8-8b25-ea9aed42003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Training Set into Training (70%) and Validation (15%)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_full, Y_train_full, test_size=VAL_SIZE_RATIO, random_state=42, stratify=Y_train_full\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904cf3e-cc3c-4246-bb1c-26c5cbd3f60b",
   "metadata": {},
   "source": [
    "## 5. DATA PREPROCESSING (CORRECTED: SCALE AFTER SPLIT) (10% Grading Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22724a4c-9699-4a6e-92a2-43fab7197ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# 5.1. Fit ONLY on Training Data\n",
    "X_train_scaled = scaler.fit_transform(X_train) # <-- CORRECT: Fit only on training data\n",
    "\n",
    "# 5.2. Transform Validation and Test Data using Training Data's statistics\n",
    "X_val_scaled = scaler.transform(X_val)       # <-- CORRECT: Transform (no fit)\n",
    "X_test_scaled = scaler.transform(X_test)     # <-- CORRECT: Transform (no fit)\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "print(f\"\\nData successfully split and scaled (Test Set leakage fixed).\")\n",
    "print(f\"Input Dimension: {input_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb901a-a97a-4a90-8cb0-3ac2a1ec7a6c",
   "metadata": {},
   "source": [
    "## 6. MODEL ARCHITECTURE DEFINITION (Standard DNN - Enhanced Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1d5c6-a23f-4038-bdb6-98662215b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_dnn(input_dim):\n",
    "    # Sequential API is used for the straightforward linear stack (Baseline)\n",
    "    model = Sequential(name=\"Baseline_DNN_M1\")  # Removed the extra comma\n",
    "    return model\n",
    "\n",
    "model_m1 = create_baseline_dnn(input_dim)\n",
    "print(\"\\nModel Architecture (DNN Baseline):\")\n",
    "model_m1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9d4d6-556d-4867-a05d-99ee73c17cce",
   "metadata": {},
   "source": [
    "## 7. MODEL COMPILATION AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5056b-9e40-4d26-8089-888f79dbfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define your model with layers\n",
    "model_m1 = tf.keras.Sequential(name=\"Baseline_DNN_M1\")\n",
    "\n",
    "# Add layers to your model\n",
    "model_m1.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model_m1.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model_m1.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "# Now compile the model\n",
    "model_m1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')] \n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,          \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"\\nStarting Model Training (Max 200 epochs, controlled by EarlyStopping)...\")\n",
    "history_m1 = model_m1.fit(\n",
    "    X_train_scaled, Y_train,\n",
    "    epochs=200,             \n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_scaled, Y_val), # Use scaled validation data\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3f2e81-b616-4cc5-9064-38751104970d",
   "metadata": {},
   "source": [
    "## 8. MODEL EVALUATION (5% Grading Weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1c2f3-ad25-40e5-a721-8b6fe9e1d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating Model on the held-out Test Set (15%):\")\n",
    "loss_m1, accuracy_m1, auc_m1 = model_m1.evaluate(X_test_scaled, Y_test, verbose=0) # Use scaled test data\n",
    "\n",
    "print(f\"\\n--- Chathuka (Baseline DNN) Final Test Results ---\")\n",
    "print(f\"Test Loss: {loss_m1:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_m1:.4f}\")\n",
    "print(f\"Test AUC-ROC: {auc_m1:.4f}\")\n",
    "\n",
    "# Generate detailed classification report for comprehensive comparison\n",
    "Y_pred_prob = model_m1.predict(X_test_scaled)\n",
    "Y_pred_class = (Y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "report = classification_report(Y_test, Y_pred_class, target_names=encoder.classes_)\n",
    "print(\"\\nClassification Report (Key Metrics for Comparison):\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec0c75",
   "metadata": {},
   "source": [
    "## 9. COMPREHENSIVE MODEL VISUALIZATION AND ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1. Training History Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training history - Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history_m1.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history_m1.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot training history - Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history_m1.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history_m1.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot training history - AUC\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history_m1.history['auc'], label='Training AUC', linewidth=2)\n",
    "plt.plot(history_m1.history['val_auc'], label='Validation AUC', linewidth=2)\n",
    "plt.title('Model AUC Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training completed after {len(history_m1.history['loss'])} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7699b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2. Confusion Matrix Visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Normalized Confusion Matrix\n",
    "cm_normalized = confusion_matrix(Y_test, Y_pred_class, normalize='true')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'],\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix details\n",
    "print(\"Confusion Matrix Analysis:\")\n",
    "print(f\"True Negatives (Benign correctly predicted): {cm[0,0]}\")\n",
    "print(f\"False Positives (Benign predicted as Malignant): {cm[0,1]}\")\n",
    "print(f\"False Negatives (Malignant predicted as Benign): {cm[1,0]}\")\n",
    "print(f\"True Positives (Malignant correctly predicted): {cm[1,1]}\")\n",
    "print(f\"Total Test Samples: {cm.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3. ROC Curve and Precision-Recall Curve\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(Y_test, Y_pred_prob)\n",
    "avg_precision = average_precision_score(Y_test, Y_pred_prob)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'PR Curve (AP = {avg_precision:.4f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction Probability Distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(Y_pred_prob[Y_test == 0], bins=30, alpha=0.7, label='Benign', color='lightblue', density=True)\n",
    "plt.hist(Y_pred_prob[Y_test == 1], bins=30, alpha=0.7, label='Malignant', color='lightcoral', density=True)\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', label='Decision Threshold')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Prediction Probability Distribution', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b3cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.4. Model Performance Metrics Bar Chart\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate metrics for both classes\n",
    "precision_benign = precision_score(Y_test, Y_pred_class, pos_label=0)\n",
    "recall_benign = recall_score(Y_test, Y_pred_class, pos_label=0)\n",
    "f1_benign = f1_score(Y_test, Y_pred_class, pos_label=0)\n",
    "\n",
    "precision_malignant = precision_score(Y_test, Y_pred_class, pos_label=1)\n",
    "recall_malignant = recall_score(Y_test, Y_pred_class, pos_label=1)\n",
    "f1_malignant = f1_score(Y_test, Y_pred_class, pos_label=1)\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_m1\n",
    "overall_precision = precision_score(Y_test, Y_pred_class, average='weighted')\n",
    "overall_recall = recall_score(Y_test, Y_pred_class, average='weighted')\n",
    "overall_f1 = f1_score(Y_test, Y_pred_class, average='weighted')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Per-class metrics\n",
    "plt.subplot(2, 2, 1)\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "benign_scores = [precision_benign, recall_benign, f1_benign]\n",
    "malignant_scores = [precision_malignant, recall_malignant, f1_malignant]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, benign_scores, width, label='Benign', color='lightblue', alpha=0.8)\n",
    "plt.bar(x + width/2, malignant_scores, width, label='Malignant', color='lightcoral', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.ylim([0, 1.1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (b, m) in enumerate(zip(benign_scores, malignant_scores)):\n",
    "    plt.text(i - width/2, b + 0.01, f'{b:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    plt.text(i + width/2, m + 0.01, f'{m:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Overall metrics\n",
    "plt.subplot(2, 2, 2)\n",
    "overall_metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "overall_scores = [overall_accuracy, overall_precision, overall_recall, overall_f1, auc_m1]\n",
    "\n",
    "bars = plt.bar(overall_metrics, overall_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'], alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Overall Model Performance', fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 1.1])\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, overall_scores):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{score:.3f}', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Feature importance visualization (using correlation with target)\n",
    "plt.subplot(2, 2, 3)\n",
    "# Get top 10 most correlated features\n",
    "top_features = corr_best.drop('diagnosis_numeric').nlargest(10)\n",
    "plt.barh(range(len(top_features)), top_features.values, color='skyblue', alpha=0.8)\n",
    "plt.yticks(range(len(top_features)), top_features.index, fontsize=10)\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.title('Top 10 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Model comparison with baseline (random classifier)\n",
    "plt.subplot(2, 2, 4)\n",
    "models = ['Random\\nClassifier', 'Our DNN\\nModel']\n",
    "accuracies = [0.5, overall_accuracy]  # Random classifier has 50% accuracy for balanced classes\n",
    "aucs = [0.5, auc_m1]  # Random classifier has 0.5 AUC\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, accuracies, width, label='Accuracy', color='lightgreen', alpha=0.8)\n",
    "plt.bar(x + width/2, aucs, width, label='AUC-ROC', color='orange', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model vs Random Classifier', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.ylim([0, 1.1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (acc, auc_val) in enumerate(zip(accuracies, aucs)):\n",
    "    plt.text(i - width/2, acc + 0.01, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    plt.text(i + width/2, auc_val + 0.01, f'{auc_val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5. Model Architecture Visualization and Summary\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Model architecture diagram\n",
    "plt.subplot(2, 1, 1)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Define layer positions and sizes\n",
    "layers = [\n",
    "    {'name': 'Input Layer', 'neurons': 30, 'pos': (1, 0.5), 'color': 'lightblue'},\n",
    "    {'name': 'Hidden Layer 1', 'neurons': 64, 'pos': (3, 0.5), 'color': 'lightgreen'},\n",
    "    {'name': 'Hidden Layer 2', 'neurons': 32, 'pos': (5, 0.5), 'color': 'lightcoral'},\n",
    "    {'name': 'Output Layer', 'neurons': 1, 'pos': (7, 0.5), 'color': 'lightyellow'}\n",
    "]\n",
    "\n",
    "# Draw layers\n",
    "for i, layer in enumerate(layers):\n",
    "    # Draw rectangle for layer\n",
    "    rect = patches.Rectangle((layer['pos'][0]-0.3, layer['pos'][1]-0.2), 0.6, 0.4, \n",
    "                           linewidth=2, edgecolor='black', facecolor=layer['color'], alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add layer text\n",
    "    plt.text(layer['pos'][0], layer['pos'][1], f\"{layer['name']}\\n({layer['neurons']} neurons)\", \n",
    "             ha='center', va='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # Draw arrows between layers\n",
    "    if i < len(layers) - 1:\n",
    "        plt.arrow(layer['pos'][0] + 0.3, layer['pos'][1], 0.4, 0, \n",
    "                 head_width=0.05, head_length=0.1, fc='black', ec='black')\n",
    "\n",
    "plt.xlim(0, 8)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Neural Network Architecture', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "\n",
    "# Model summary table\n",
    "plt.subplot(2, 1, 2)\n",
    "ax = plt.gca()\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create summary data\n",
    "summary_data = [\n",
    "    ['Layer Type', 'Output Shape', 'Parameters', 'Activation'],\n",
    "    ['Dense (Input)', f'(None, 64)', f'{30 * 64 + 64:,}', 'ReLU'],\n",
    "    ['Dense (Hidden)', f'(None, 32)', f'{64 * 32 + 32:,}', 'ReLU'],\n",
    "    ['Dense (Output)', f'(None, 1)', f'{32 * 1 + 1:,}', 'Sigmoid'],\n",
    "    ['', '', '', ''],\n",
    "    ['Total Parameters', '', f'{(30*64+64) + (64*32+32) + (32*1+1):,}', ''],\n",
    "    ['Training Data', f'{X_train_scaled.shape[0]} samples', '', ''],\n",
    "    ['Validation Data', f'{X_val_scaled.shape[0]} samples', '', ''],\n",
    "    ['Test Data', f'{X_test_scaled.shape[0]} samples', '', '']\n",
    "]\n",
    "\n",
    "table = plt.table(cellText=summary_data, cellLoc='center', loc='center',\n",
    "                 colWidths=[0.25, 0.25, 0.25, 0.25])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style the header row\n",
    "for i in range(4):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Style the summary rows\n",
    "for i in range(4):\n",
    "    table[(5, i)].set_facecolor('#E3F2FD')\n",
    "    table[(6, i)].set_facecolor('#E3F2FD')\n",
    "    table[(7, i)].set_facecolor('#E3F2FD')\n",
    "    table[(8, i)].set_facecolor('#E3F2FD')\n",
    "\n",
    "plt.title('Model Summary and Dataset Information', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed model performance summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           COMPREHENSIVE MODEL PERFORMANCE REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📊 Dataset: Breast Cancer Wisconsin (Diagnostic)\")\n",
    "print(f\"📈 Model: Deep Neural Network (3-layer architecture)\")\n",
    "print(f\"🎯 Task: Binary Classification (Malignant vs Benign)\")\n",
    "print(\"\\n📋 FINAL TEST RESULTS:\")\n",
    "print(f\"   ✅ Test Accuracy: {accuracy_m1:.4f} ({accuracy_m1*100:.2f}%)\")\n",
    "print(f\"   ✅ Test AUC-ROC:  {auc_m1:.4f} ({auc_m1*100:.2f}%)\")\n",
    "print(f\"   ✅ Test Loss:     {loss_m1:.4f}\")\n",
    "print(f\"   ✅ Precision:     {overall_precision:.4f} ({overall_precision*100:.2f}%)\")\n",
    "print(f\"   ✅ Recall:        {overall_recall:.4f} ({overall_recall*100:.2f}%)\")\n",
    "print(f\"   ✅ F1-Score:      {overall_f1:.4f} ({overall_f1*100:.2f}%)\")\n",
    "print(\"\\n🏆 MODEL EXCELLENCE INDICATORS:\")\n",
    "print(f\"   • High Accuracy: {accuracy_m1:.1%} - Excellent overall performance\")\n",
    "print(f\"   • High AUC-ROC: {auc_m1:.1%} - Outstanding discrimination ability\")\n",
    "print(f\"   • Low Loss: {loss_m1:.4f} - Well-calibrated predictions\")\n",
    "print(f\"   • Balanced Performance: Good precision and recall for both classes\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65118f27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f888d-5d1e-4fb6-a2ad-ec52a99c0917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
